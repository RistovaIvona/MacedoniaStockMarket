{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import itertools\n",
    "import regex as re\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Activation, Dropout\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tmp/mse_raw.csv', parse_dates=['date', 'start_date'], index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>average</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>quantity</th>\n",
       "      <th>change %</th>\n",
       "      <th>volume total</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALK</td>\n",
       "      <td>1997-01-09</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>279270.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279270.0</td>\n",
       "      <td>1997-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ALK</td>\n",
       "      <td>1997-01-10</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ALK</td>\n",
       "      <td>1997-01-11</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ALK</td>\n",
       "      <td>1997-01-12</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ALK</td>\n",
       "      <td>1997-01-13</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1997-01-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id       date    open    high     low  average   close    volume  \\\n",
       "0       ALK 1997-01-09  1070.0  1070.0  1070.0   1070.0  1070.0  279270.0   \n",
       "22      ALK 1997-01-10  1070.0  1070.0  1070.0   1070.0  1070.0       0.0   \n",
       "44      ALK 1997-01-11  1070.0  1070.0  1070.0   1070.0  1070.0       0.0   \n",
       "66      ALK 1997-01-12  1070.0  1070.0  1070.0   1070.0  1070.0       0.0   \n",
       "88      ALK 1997-01-13  1070.0  1070.0  1070.0   1070.0  1070.0       0.0   \n",
       "\n",
       "    quantity  change %  volume total start_date  \n",
       "0      261.0       0.0      279270.0 1997-01-09  \n",
       "22       0.0       0.0           0.0 1997-01-09  \n",
       "44       0.0       0.0           0.0 1997-01-09  \n",
       "66       0.0       0.0           0.0 1997-01-09  \n",
       "88       0.0       0.0           0.0 1997-01-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting RNN ALK dataset for training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alk_df = df[df.stock_id == 'ALK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date', 'open', 'high', 'low', 'average', 'close', 'volume',\n",
       "       'quantity', 'change %', 'volume total', 'start_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alk_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with only closing price column\n",
    "close_price = alk_df['close']\n",
    "\n",
    "#Convert the dataframe into numpy array\n",
    "close_price = close_price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8630,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = scaler.fit_transform(close_price.reshape(len(close_price), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04175824],\n",
       "       [0.04175824],\n",
       "       [0.04175824],\n",
       "       ...,\n",
       "       [0.86373626],\n",
       "       [0.86373626],\n",
       "       [0.85714286]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### univariate sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples with one day prediciton\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]] [0.04175824]\n",
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]] [0.04175824]\n",
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]] [0.04029304]\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(scaled_df, n_steps)\n",
    "# summarize the data\n",
    "for i in range(3):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM, one day prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X[:int(len(X)-60),], X[int(len(X)-60):int(len(X)-1),], X[int(len(X)-1):,]\n",
    "y_train, y_valid, y_test = y[:int(len(X)-60),], y[int(len(X)-60):int(len(X)-1),], y[int(len(X)-1):,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8567, 3, 1), (59, 3, 1), (1, 3, 1), (8567, 1), (59, 1), (1, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], X_valid.shape[1], n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "rmse = RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(optimizer):\n",
    "    #initialisizng the model \n",
    "    regression= Sequential()\n",
    "\n",
    "    #First Input layer and LSTM layer with 0.2% dropout\n",
    "    regression.add(LSTM(units=50,return_sequences=True,kernel_initializer='glorot_uniform',input_shape=(X_train.shape[1],1)))\n",
    "    regression.add(Dropout(0.2))\n",
    "\n",
    "    # Second LSTM layer with 0.2% dropout\n",
    "    regression.add(LSTM(units=50,kernel_initializer= 'glorot_uniform',return_sequences=True))\n",
    "    regression.add(Dropout(0.2))\n",
    "\n",
    "    #Third LSTM layer with 0.2% dropout\n",
    "    regression.add(LSTM(units=50,kernel_initializer='glorot_uniform',return_sequences=True))\n",
    "    regression.add(Dropout(0.2))\n",
    "\n",
    "    #Fourth LSTM layer with 0.2% dropout, we wont use return sequence true in last layers as we dont want to previous output\n",
    "    regression.add(LSTM(units=50,kernel_initializer='glorot_uniform'))\n",
    "    regression.add(Dropout(0.2))\n",
    "    #Output layer , we wont pass any activation as its continous value model\n",
    "    regression.add(Dense(units=1))\n",
    "\n",
    "    #Compiling the network\n",
    "    regression.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "    \n",
    "    return regression\n",
    "\n",
    "model= KerasRegressor(build_fn=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "parameters = {'batch_size': [50, 32],\n",
    "              'epochs': [50, 25],\n",
    "              'optimizer': ['adam']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callback1 = ModelCheckpoint('vanila_best.pt', verbose=1, save_best_only=True, mode='min', monitor='val_loss')\n",
    "my_callback2 = EarlyStopping(patience=10)\n",
    "\n",
    "my_callbacks = [my_callback1, my_callback2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F25AD0BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F25AD0BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0231\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0018\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0015\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0013\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.8668e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0010\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6506e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.1917e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.5659e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2284e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 8.6478e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.3328e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.6012e-04: 0s - loss: 8.60\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.3035e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.5554e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.2751e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.9682e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.0508e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.0407e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.9031e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.5787e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.5747e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.8549e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.1542e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.3608e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.9468e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.0714e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.6726e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.6665e-04\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.5597e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.3935e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.5522e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.2656e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.0735e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.5400e-04: 0s - loss: 5.51\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.4126e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.5403e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.7947e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.6797e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.2400e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.1943e-04\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.7088e-04: 0s -\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.6671e-04\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.0595e-04\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.6905e-04\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.5826e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F263BC7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F263BC7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.7180e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F34DAC2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F34DAC2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0017\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0012\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0011\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.9346e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.8113e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.2600e-04\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 13ms/step - loss: 9.4401e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.1894e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.1552e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.1963e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.4314e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.5391e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.3442e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.9969e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.4550e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.2727e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.0922e-04: 0s - loss: 7.\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.6738e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.8312e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.3140e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.9616e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.7637e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.0143e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.5785e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.0856e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.4584e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7464e-04\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.6084e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.3190e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.0387e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.1968e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.0260e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.2256e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.7480e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.8691e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.7846e-0 - 2s 13ms/step - loss: 5.7969e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7240e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.7401e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.9886e-04\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.7763e-04\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.9512e-04\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.9094e-04\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.8079e-04\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.9252e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F32645C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F32645C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7.3936e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F32645B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F32645B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0154\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0013\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0011: 0s - loss: 0.0\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.5732e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.7112e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.6839e-04\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.8937e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.2688e-04\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.0127e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.2843e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 6.9575e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 7.1377e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.7355e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.4128e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.5415e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.8094e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.9771e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 6.3239e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.0502e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5783e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 5.9235e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.5618e-04: 1\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.4067e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.1388e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.4780e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.2953e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.1279e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.3342e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.9911e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.4853e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.9779e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.8013e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.7277e-04: 1s\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.6552e-04\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 12ms/step - loss: 5.0981e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.9109e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.5252e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.1147e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.8326e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.7826e-04: 0s - loss:\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.6324e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.0005e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.4993e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.7635e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.8072e-04\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.5742e-04\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.6717e-04\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.6936e-04\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.7227e-04\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.6676e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F261B82F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F261B82F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.3254e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3932D400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3932D400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0206\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0017\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0014\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0013\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0012\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0012: \n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0010\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.9152e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.8892e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.4366e-04: 1s \n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.4146e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.9907e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.7112e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.4397e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.4199e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.0509e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.5509e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.5236e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.1502e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.4471e-04: 0s -\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.8697e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.6019e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.5060e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.6064e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.1159e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.9780e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.5019e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.6153e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.0760e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7913e-04: 1\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.2411e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.9008e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.8731e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.0941e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7161e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.4335e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.6927e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.6941e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.0896e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.9015e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8640e-0 - 2s 13ms/step - loss: 6.8515e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.6343e-04\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.8559e-04\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.4020e-04\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.5517e-04\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7288e-04\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.5910e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F36FC7620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F36FC7620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 4ms/step - loss: 2.1697e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F32645158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F32645158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0140\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0010\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.2401e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.8444e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.9318e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.3570e-04: \n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.7370e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.3228e-04\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.2374e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.7410e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.0375e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.1903e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.2921e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.3641e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.5508e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.7655e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.5318e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.9883e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.3849e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.3609e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.0518e-04: 0s - loss: 4.9543e- - ETA: 0s - loss: 4.97\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.2716e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.5099e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.4123e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.5599e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.7043e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.6311e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.3538e-04\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.3551e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.2576e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.4850e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.7262e-04: 0s - loss:\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.5988e-04\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.9323e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.7829e-04\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.3902e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.3361e-04\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.0947e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.2500e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.2106e-04\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.5088e-04\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.4028e-04\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.0258e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 3.9213e-04\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.2137e-04: 0s - loss: 4.051\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 3.9020e-04\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.1080e-04: 0s \n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.0313e-04\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 4.4881e-04\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 4.0443e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3FE94A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3FE94A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3935A1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3935A1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0233\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0017\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0014\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0013\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0012\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0011\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.9375e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0010\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.7677e-04\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.9654e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.3261e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.4762e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.4701e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.0695e-04: 0s \n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.0245e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.5248e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.4468e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.4661e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.9167e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.3699e-04:\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.7283e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.7426e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F40F78378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F40F78378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 8.4574e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3A58CF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3A58CF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0206\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0018\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0014\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0014\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0012\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0012\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0011\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0010\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0010\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0010\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.6764e-04\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.6833e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.1986e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.1875e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.0868e-04: 1s\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.8284e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.1130e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.6935e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 8.1431e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.2774e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.7359e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.9587e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.0536e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.6719e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4344DB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4344DB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.0389e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4215A620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4215A620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0159\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 0.0012\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.9640e-04\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 8.7873e-04\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.9175e-04\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.9305e-04\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.4534e-04\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.5132e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.2227e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 7.6770e-04\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.8426e-04\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 15ms/step - loss: 6.5288e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 6.7655e-04: 0s - loss: 7.09 - ETA: 0s - loss: \n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.1772e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.5611e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 6.0260e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.7986e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.8564e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.9179e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5826e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5532e-04: 0s - loss: 5.5\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.3348e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.5694e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 5.2798e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3DC14400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3DC14400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2.8911e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F2280AF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F2280AF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0210\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0017\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0015\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0013: 0s - loss: 0.\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0011\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 0.0012\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0011\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.6987e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0010\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.4048e-04\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0011\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.5160e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.5702e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 8.8810e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 8.5879e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 8.8261e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.4920e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.0990e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 7.8446e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.3540e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 8.0839e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.7856e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.7566e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3DB6B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3DB6B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.4091e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4108E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4108E730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 0.0112\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 0.0010\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 9.4113e-04: 0s -\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.2079e-04\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 2s 18ms/step - loss: 7.4198e-04: 0s - loss: 7.4493e-0\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 6.7814e-04\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 7.5825e-04\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.4634e-04\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 6.5354e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 6.0708e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 6.2115e-04\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.6771e-04\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5380e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.6183e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.1542e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.1122e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.0938e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.0407e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.1056e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.1095e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5395e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.8657e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 4.8467e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.1256e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 5.0149e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3FEB17B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3FEB17B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F326450D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F326450D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0175\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0016\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0014\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0010\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.1250e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.8426e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.2205e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.9571e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.2828e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.3995e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.3668e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.2553e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.9527e-04: 0s - loss: 6.9042\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.9001e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.2826e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.7304e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.4494e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.1432e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.8230e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.8978e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.9434e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.0189e-04: 0s - loss: 6.0446e\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.6621e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.7592e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.2544e-04: 0s - l\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.7289e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.7761e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.6492e-04: 0s - loss: 5.6453\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 5.2610e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.8565e-04\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.3340e-04: 0s - \n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.3740e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.4261e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.5791e-04\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.2894e-04\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.1508e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.5269e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.2960e-04\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.2721e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.2125e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 5.4363e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.2245e-04:\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.1117e-04\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.7531e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.3151e-04\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.9155e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F479F6378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F479F6378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 4ms/step - loss: 6.5294e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F261B7158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F261B7158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0144\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0015\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0013\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 9.8426e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 9.4564e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.5437e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.1652e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 8.9832e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.5789e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.2991e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.7753e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.0610e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.4569e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.9863e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.1850e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.6571e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.5391e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.3594e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.9844e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.7292e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 6.8697e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.9208e-04 - ETA: 0s - loss: 7 - ETA: 0s - loss: 6.9264e-0\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.2562e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.0691e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.9863e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.5247e-04: 0s - loss: 6.4533\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.6389e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.6595e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.3230e-04\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.9877e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.0813e-04: 0s - loss: 5.94\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.3084e-04: 0s - \n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 6.1957e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.9820e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.3632e-04\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.8020e-04: 0s - loss\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.8503e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.2008e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.2104e-04: \n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.8972e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.9121e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.7437e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.3773e-04\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 6.0835e-04: 0s - \n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.9839e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.0736e-04\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.6686e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3B755488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F3B755488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.9398e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3B5CC620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3B5CC620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0109\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0011\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.9188e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.1440e-04: 0s - loss: 9.2369e\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.2645e-04\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 8.3344e-04\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 7.2755e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.2654e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.8674e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.8212e-04\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 2s 11ms/step - loss: 6.9993e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 6.7729e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.1764e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 6.6380e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.0622e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.6956e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.7696e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 5.5036e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.1354e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.0692e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.5730e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.3314e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.4685e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 4.9991e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 4.9459e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 5.6914e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.7601e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.0201e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.1713e-04\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 4.5949e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.0909e-04: \n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 4.9666e-04\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.0045e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.6886e-04\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.5984e-04\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 4.9387e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.1382e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.0543e-04: 1s - lo - ETA: 0s - loss: 5.14\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.1334e-04\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.8727e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.7222e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.8341e-04\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.4860e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 4.8531e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 4.4295e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.9537e-04\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.8133e-04\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.9061e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.9707e-04\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 4.7601e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F479C9400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F479C9400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 2.3443e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3DBACE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3DBACE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0153\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0016\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0013\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.001 - 3s 12ms/step - loss: 0.0010\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.7930e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.7690e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.6434e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 8.7477e-04: 0s - loss: 8.7674e-0\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.1471e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.1662e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.1193e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.3493e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.8337e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 8.2086e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.5778e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.7313e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.6962e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.4067e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.8620e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.0314e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.0811e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.9946e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.0144e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.3501e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.5437e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.1690e-04\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.6750e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.3481e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.2358e-04\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 3s 13ms/step - loss: 6.8524e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.8581e-04\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.8321e-04\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.7850e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.3965e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.8251e-04\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.8101e-04\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.9712e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.0890e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.4253e-04: 0s - loss: 7.\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.6609e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.3878e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.9446e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.3354e-04\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.9563e-04\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.7690e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.7794e-04: 0s - loss:\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.6562e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F49DCFB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F49DCFB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.7820e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F49E229D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F49E229D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0095: 0s - loss: 0.\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 9.1537e-04\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 8.0474e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.2262e-04\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.4519e-04\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.7176e-04\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 5.8933e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 6.9464e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 5.7895e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.0176e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 5.2015e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.1509e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.8698e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.3319e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 5.2283e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 5.4322e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.5406e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 4.7110e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.5200e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.0905e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 4.6507e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.7944e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.3622e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.2847e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.5729e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 3.9865e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 4.6797e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 4.5419e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 4.4121e-04\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 4.3839e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 4.3202e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 4.0155e-04\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 4.4658e-04: 0s - loss: 4.375\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 4.2145e-04\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.1943e-04\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 4.1190e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 4.2318e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.2932e-04\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.3866e-04\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.1474e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.4747e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.1828e-04\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.0641e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.0539e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.1753e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.2702e-04\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 4.2805e-04\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 4.1730e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 3.9179e-04\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 4.1029e-04: 1s - loss: 3.8349e - ETA\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F51607F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F51607F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9627e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4C06BD90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4C06BD90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0158: 1s - loss: - ETA\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0016\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0013\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0011\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0011\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0011\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0010\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.6851e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 9.2085e-04\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 9.1247e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.6057e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 8.1764e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.4774e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.4720e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.1909e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 7.1198e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.5558e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 7.0724e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.5191e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.0380e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 6.2982e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 5.9526e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 5.2741e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 5.8246e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 6.0740e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F117950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F117950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 4.6403e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4C06B950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4C06B950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0152\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0016\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0015\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0013\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0011: 0s - loss: 0.001\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0010\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0010\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.6628e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0010\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.1191e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.6665e-04:\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.1789e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 8.5923e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 8.0151e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.2808e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.3750e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 7.7730e-04: 1\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 7.3674e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.3099e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.7014e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 6.4054e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 6.7901e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.7825e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 6.7614e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.6953e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F53DC5D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F53DC5D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 4ms/step - loss: 7.5262e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F47956510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F47956510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0100\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0011\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 9.8738e-04\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 9.7910e-04\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 8.5226e-04\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 8.2513e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.7989e-04\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 7.5978e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.8822e-04\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 6.2931e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.9988e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 6.2093e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 6.4863e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 6.6381e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 5.3072e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 6.2014e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 5.8399e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 5.6899e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 5.4011e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 5.1833e-04: 1s - loss: 4.8754e - ETA: 0s -\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 5.5045e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 4.8888e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 5.3611e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 5.1147e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 4.7729e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AFF0378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AFF0378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.8636e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F528C62F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F528C62F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0143\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0016\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0013: 1 - ETA: 0s - \n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0012: 0s - los\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0012\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0012\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.0010\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0010\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0010\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 9.8665e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 9.2792e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 9.0186e-04: 0s - loss: 8.890\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 9.1134e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 8.5612e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 8.2948e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 8.0493e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.6220e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 7.7350e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 7.7896e-04: 0s - loss: \n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 7.8778e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.2596e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.0616e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 7.0611e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.4702e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 7.2929e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F52ADCA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F52ADCA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 5ms/step - loss: 7.4008e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F5A8809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F5A8809D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0096\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0011\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 8.2160e-04: 2s - loss - ETA: 2s - loss: 8.622\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 7.1897e-04: 0s - lo - ETA: 0s - loss: 7.2892\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 7.5040e-04\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 7.0393e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 6.3242e-04\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 6.7125e-04: 0s - loss: 6.77\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 6.1756e-04: 0s - loss: 6.\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 5.6999e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 5.6546e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 5.7036e-04: 2s - loss: 6 - ETA: 1s - loss: 5. - ETA\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 5.1361e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 5.0870e-04: 0s - lo\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 5.0084e-04: 1s\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 4.9205e-04: 0s - loss: \n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 5.1262e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 4.7771e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 4.5150e-04ETA: 1s - loss: 4 - ETA: 0s - loss: 4.4326e-0 - ETA: 0s\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 4.7932e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 4.9636e-04: 0s - los\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 4.8152e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 4.2813e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 4.7138e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 4.2244e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AF30158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AF30158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.4060e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4AEA0378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4AEA0378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0107\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0012\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0011\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0010: 0\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 9.3821e-04\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 8.8694e-04\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 8.7915e-04\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 8.1887e-04\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 8.2430e-04\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 6.9648e-04\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 7.4029e-04\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 6.7389e-04\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 6.9274e-04\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 6.8405e-04\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 6.6392e-04\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.3314e-04\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 6.0228e-04\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 6.4742e-04\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 6.0905e-04\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.8995e-04\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 6s 23ms/step - loss: 5.5892e-04: 1s \n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 7s 25ms/step - loss: 5.7584e-04\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 5.9020e-04\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.7026e-04\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 6.0791e-04: 0s - loss: 6\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.8037e-04\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.9814e-04\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.7079e-04\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 5.6929e-04\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.8120e-04\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.5313e-04\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.5386e-04\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.0511e-04: 1s \n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 4s 16ms/step - loss: 5.6427e-04: 1s - loss: 5.6501e - ETA: 1s \n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 5.9538e-04\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 5.4413e-04\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.4930e-04\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.4126e-04\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.5755e-04: 1s -\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 5.3608e-04\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 5.7611e-04\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 5.6859e-04\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 5.4111e-04\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 7s 26ms/step - loss: 5.2412e-04\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 5.7465e-04\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 5.2504e-04TA: 0s - loss: 5.3\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.0115e-04\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.3402e-04: \n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.0130e-04\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.4375e-04\n"
     ]
    }
   ],
   "source": [
    "grid_search = RandomizedSearchCV(estimator = model,param_distributions=parameters,n_iter=5)\n",
    "# fitting the model and Calculating the best parameters.\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F65B78A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F65B78A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0113\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0013\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0011\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.7102e-04\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.1185e-04\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 9.3507e-04\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 8.9678e-04\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 8.3662e-04:  - ETA: 2s - loss: \n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 7.5715e-04\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 7.8264e-04\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 7.6015e-04\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.9114e-04\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 6.2854e-04\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.8934e-04\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.5785e-04\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 6.0301e-04\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 6.0298e-04\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 6.0025e-04\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.6730e-04\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.7443e-04\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.7739e-04\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.8894e-04\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.2579e-04\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 6.0086e-04\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.3944e-04\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.7050e-04\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.6274e-04: 0s - loss: 5.5\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.7997e-04\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.7367e-04: 1s -\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.5144e-04\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.8519e-04\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - ETA: 0s - loss: 5.6185e-04 - 5s 18ms/step - loss: 5.6187e-04\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 5.8007e-04: \n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 5.5449e-04\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.5180e-04\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.5280e-04\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.7334e-04\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.8072e-04\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.8909e-04\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 5.3518e-04\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.0083e-04: 0s - loss: 4.\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.3312e-04\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.3904e-04\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.4587e-04\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.4574e-04\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.1955e-04- ETA: 0s - loss: \n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 5.6276e-04: 0s - loss: 5.6242e-\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.3269e-04\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 5.1500e-04\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 5.3884e-04\n"
     ]
    }
   ],
   "source": [
    "model=grid_search.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000026F65CA5488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000026F65CA5488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "yhat = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "y_pred = scaler.inverse_transform(yhat.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.4619140625"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM, one day prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(optimizer):\n",
    "    regression = Sequential()\n",
    "    regression.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    regression.add(LSTM(50, activation='relu'))\n",
    "    regression.add(Dense(1))\n",
    "    regression.compile(optimizer='adam', loss='mse')\n",
    "    return regression\n",
    "\n",
    "model= KerasRegressor(build_fn=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:282: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70A3BC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70A3BC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0249\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.3582e-04: 0s - loss: 1.396 - ETA: 0s - loss: 1.3478e\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.1547e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.1026e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0992e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.1147e-04\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 1.0620e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0895e-04: 1s \n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.1024e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0913e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 1.0686e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0646e-04: 0s - loss: 1.0650e-0\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.1099e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0458e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.7635e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0425e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0443e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.1016e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0445e-04: 0s - lo\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0713e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 1.1555e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0953e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0332e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0228e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0454e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0837e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.1463e-04\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 9.8756e-05\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 9.8673e-05\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.8681e-05\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.0475e-0 - 2s 11ms/step - loss: 1.0417e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.2782e-04\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.4298e-04\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6476e-05\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.8764e-05\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0061e-04\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 9.8830e-05\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0113e-04\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.5495e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.0244e-05: \n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2107e-05\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3341e-05\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.5179e-05\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 9.2425e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 9.2738e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.4272e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.5120e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.1766e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 9.6638e-05: 0s - loss:\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 8.8419e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71DFBB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71DFBB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4.1506e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F73EFCEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F73EFCEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 0.0272\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.2100e-04\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0852e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0957e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0569e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0432e-04: 0s - loss: 1.0603e\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0811e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.0506e-04\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0985e-04: 0s - lo\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.0280e-04\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0505e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0413e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0392e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0450e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1127e-04\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0082e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.7899e-05\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0592e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0368e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0410e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0255e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 2s 15ms/step - loss: 9.6112e-05\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 2s 13ms/step - loss: 1.1342e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.6130e-05\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.5520e-05\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0094e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.5847e-05\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 2s 16ms/step - loss: 1.0388e-04:  - ETA: 1s - \n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0037e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.5644e-05\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 9.4736e-05\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 1.0131e-04: 0s - loss: 1.1\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 9.1105e-05\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0384e-04\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3799e-05\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6201e-05\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2138e-05\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.8032e-05\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0065e-04\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4125e-05\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 9.2134e-05\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.1080e-05\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 1.4717e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.7234e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 7.8699e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4551e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 7.8688e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.5819e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 8.9578e-05\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 7.7814e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F752C9B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F752C9B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 2.9935e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F77432EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F77432EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 0.0214\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 7.6617e-05\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.3311e-05\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.9826e-05\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 5.7786e-05: \n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.9650e-05\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.9243e-05\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.5399e-05\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.8120e-05\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.6260e-05\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.6424e-05\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 5.3625e-05\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 5.8263e-05\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 2s 14ms/step - loss: 5.5343e-05\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 2s 12ms/step - loss: 6.2799e-05\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 5.6476e-05\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 5.8643e-05\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.9585e-05\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.9785e-05\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.8467e-05: 0s - loss: 5.9118e\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.9469e-05\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6305e-05\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6237e-05\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.2283e-05\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7310e-05\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.4497e-05\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.4552e-05\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.5705e-05\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 6.4827e-05\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.6721e-05\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.4607e-05\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.2235e-05\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 10ms/step - loss: 5.3288e-05\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 6.3634e-05\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7267e-05\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.5325e-05A: 0s - loss: 5.5770e-\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.5080e-05\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.2879e-05\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7744e-05\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.1832e-05\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.3121e-05\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.4791e-05\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.5469e-05\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 5.1809e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 5.3760e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.2253e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.9187e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.0907e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.1803e-05\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 4.9253e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F787D7B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F787D7B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.1145e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7A944EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7A944EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0260\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.2168e-04\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.1732e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1561e-04\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.1620e-04\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1224e-04\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1359e-04\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1330e-04\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1362e-04\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1251e-04\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1208e-04\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1369e-04\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1065e-04\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.1498e-04\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0888e-04: 0s - \n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0733e-04\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1281e-04\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0858e-04\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1713e-04\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.0544e-04- ETA: 0s - loss: 1.0592e - 1s 9ms/step - loss: 1.0614e-04\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0314e-04\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0026e-04\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0620e-04\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1591e-04\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0670e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0291e-04\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 9.8709e-05\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.4491e-05: 0s - loss: 9.8\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1893e-04\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0024e-04\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0045e-04\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6563e-05\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.9621e-05\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.8670e-05\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.9446e-05\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4073e-05\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 8.9321e-05\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4995e-05\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 8.3877e-05\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.7537e-05\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 7.7835e-05\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 7.7287e-05\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1568e-04\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.5121e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.4215e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.5320e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.4472e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.0840e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 7.0267e-05\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.8203e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F774909D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F774909D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.6950e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F71CDE048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F71CDE048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "Epoch 2/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1461e-04\n",
      "Epoch 3/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0367e-04\n",
      "Epoch 4/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.6288e-05\n",
      "Epoch 5/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.4392e-05\n",
      "Epoch 6/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2061e-05\n",
      "Epoch 7/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3692e-05\n",
      "Epoch 8/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3457e-05\n",
      "Epoch 9/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2739e-05\n",
      "Epoch 10/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.4657e-05\n",
      "Epoch 11/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.1795e-05\n",
      "Epoch 12/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.1452e-05\n",
      "Epoch 13/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.1206e-05\n",
      "Epoch 14/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3557e-05\n",
      "Epoch 15/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.0807e-05\n",
      "Epoch 16/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.9936e-05\n",
      "Epoch 17/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.6417e-05\n",
      "Epoch 18/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.0302e-05\n",
      "Epoch 19/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3238e-05\n",
      "Epoch 20/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 8.7557e-05\n",
      "Epoch 21/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.0043e-05\n",
      "Epoch 22/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.7221e-05\n",
      "Epoch 23/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.8903e-05\n",
      "Epoch 24/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2007e-05\n",
      "Epoch 25/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0075e-04\n",
      "Epoch 26/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.4807e-05\n",
      "Epoch 27/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.7418e-05\n",
      "Epoch 28/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4683e-05\n",
      "Epoch 29/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.3711e-05\n",
      "Epoch 30/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.8344e-05\n",
      "Epoch 31/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4566e-05\n",
      "Epoch 32/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.5554e-05\n",
      "Epoch 33/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.8942e-05\n",
      "Epoch 34/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.8063e-05\n",
      "Epoch 35/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.3283e-05\n",
      "Epoch 36/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.5594e-05\n",
      "Epoch 37/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.8608e-05\n",
      "Epoch 38/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.1004e-05\n",
      "Epoch 39/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.6734e-05\n",
      "Epoch 40/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.4397e-05\n",
      "Epoch 41/50\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.6724e-05\n",
      "Epoch 42/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.6745e-05\n",
      "Epoch 43/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 8.0288e-05\n",
      "Epoch 44/50\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 7.7086e-05\n",
      "Epoch 45/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.8009e-05\n",
      "Epoch 46/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.8115e-05\n",
      "Epoch 47/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.3364e-05\n",
      "Epoch 48/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.1102e-05\n",
      "Epoch 49/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.5321e-05\n",
      "Epoch 50/50\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 7.5170e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F5A7BB730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F5A7BB730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.3586e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3B929840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F3B929840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0333\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.8165e-04\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.2032e-04: 0s - loss: 1\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1332e-04\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1342e-04\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1021e-04\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1192e-04\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0828e-04\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.3486e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0672e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0859e-04\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0631e-04\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0691e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0616e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0703e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1430e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0341e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0332e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1100e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.3760e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0901e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0438e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0830e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0257e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0667e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7882FC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7882FC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.0862e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F75197B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F75197B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0265\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1119e-04\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0537e-04\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0458e-04\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0506e-04\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0347e-04\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0720e-04\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0656e-04\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0450e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0707e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0748e-04\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0367e-04: 0s - loss: 1.056\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0421e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0816e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0295e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0502e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0340e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0273e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0663e-04: 0s - los\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.9404e-05\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.8425e-05\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6956e-05\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.8551e-05\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1074e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0435e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F0FCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F0FCBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.6206e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F71D04B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F71D04B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 0.0250\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.6222e-05\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.8850e-05\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.0642e-05: 0s - loss: 5.8472e-0\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 5.7841e-05\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 2s 11ms/step - loss: 5.6271e-05: 0s - loss: 5.\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7616e-05\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.5201e-05\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6431e-05\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6541e-05\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.8413e-05\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.6985e-05\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.5230e-05\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6154e-05\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7529e-05\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6096e-05: 0s \n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.6607e-05\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 6.0543e-05\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 5.9825e-05\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 6.1036e-05\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7384e-05\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.7156e-05\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 6.4831e-05\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.5451e-05\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 5.8681e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AFE5BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AFE5BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2.3771e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70BA7BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70BA7BF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0258\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.5323e-04- ETA - 1s 10ms/step - loss: 1.5270e-04\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.2208e-04\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1540e-04: 0s - loss:\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.2205e-04\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.2027e-04\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1651e-04\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1603e-04\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1639e-04\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1661e-04\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1684e-04\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.1297e-04\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.2058e-04\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1624e-04\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1188e-04\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1343e-04\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1936e-04\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1348e-04\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0708e-04\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.1230e-04\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 1.0418e-04\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1475e-04\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0223e-04\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 1s 11ms/step - loss: 1.0163e-04\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1999e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AA8E1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AA8E1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.3523e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AB94EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AB94EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.1390e-04\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 1.0151e-04\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3359e-05\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.3194e-05\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.5824e-05\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 11ms/step - loss: 8.5943e-05\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.2430e-05: \n",
      "Epoch 9/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 9.6278e-05\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.6912e-05\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.6551e-05\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.1280e-05\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.4971e-05\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.1461e-05\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.0006e-05\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.5018e-05\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.2793e-05\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.4539e-05\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.5988e-05\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 8.3586e-05\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.9019e-05\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 9.6800e-05\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.3896e-05\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.3804e-05\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - 1s 9ms/step - loss: 8.6888e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7BF3CB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7BF3CB70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.1846e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7D0D4EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7D0D4EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0224\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 2.7053e-04\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2309e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1482e-04\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1763e-04\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1853e-04\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1269e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1362e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2520e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2590e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2483e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2169e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2310e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1568e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1184e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.3352e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1232e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2777e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1721e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1645e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1336e-04A: 0s - loss:\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1492e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1888e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1190e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1180e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2076e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1298e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1463e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1074e-04\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0977e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1877e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0663e-04\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0957e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0926e-04\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1352e-04\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0845e-04\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1273e-04\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1108e-04\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - ETA: 0s - loss: 1.0404e-0 - 2s 8ms/step - loss: 1.0429e-04\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0296e-04\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0714e-04\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0608e-04\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0182e-04\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0150e-04\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0209e-04\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.5607e-05\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.9319e-05\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0656e-04\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.5057e-05\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0376e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AB94EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AB94EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 4.5342e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70C24598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70C24598> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0198\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1569e-04\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0801e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1076e-04\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1212e-04\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0985e-04\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0965e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1647e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0715e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0543e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1419e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0519e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1074e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0190e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0786e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0746e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0550e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6193e-05\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.3983e-05\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6905e-05\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.5967e-05\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.4794e-05\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6114e-05\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.4876e-05\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.9227e-05\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.7820e-05\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.2197e-05\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.5161e-05\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.7949e-05\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.1824e-05\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.9909e-05\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.8747e-05\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.7616e-05\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.2730e-05\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.9697e-05\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.1350e-05\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.3797e-05\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.9614e-05\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.2727e-05\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.7029e-05\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.3425e-05\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 7.1664e-05\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 6.2517e-05\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.6516e-05\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.5831e-05\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.0629e-05\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.9299e-05\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.5308e-05\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9495e-05\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.7505e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F529ACF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F529ACF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 3.2647e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F528C5AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F528C5AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0142\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.1415e-05\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9943e-05\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.8545e-05\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9535e-05\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.7039e-05\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9806e-05\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.0198e-05\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.7287e-05\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9353e-05\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9965e-05\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.2628e-05\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.6677e-05\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.7064e-05\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.0571e-05\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.8858e-05\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.0405e-05\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.6192e-05\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.7512e-05\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.1033e-05\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.3186e-05\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9657e-05\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.5814e-05\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.5781e-05\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.3006e-05\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.0681e-05\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.9680e-05\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.4427e-05\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.3388e-05\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.3611e-05\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.2571e-05\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.6388e-05\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.4268e-05\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.4676e-05\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.9792e-05\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 4.9064e-05\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.4737e-05\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.7505e-05\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.6430e-05\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.5705e-05\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.0544e-05\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 5.1825e-05\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.1779e-05\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.8791e-05\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 4.2763e-05\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.1786e-05\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.2022e-05\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.9163e-05\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.1000e-05\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 4.2357e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F70A3B7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F70A3B7B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.6207e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F77490EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F77490EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2353e-04\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2111e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1815e-04\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1865e-04\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2090e-04\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1990e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1839e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1476e-04\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1657e-04\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1789e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1529e-04\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1559e-04\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.3114e-04\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2064e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1082e-04\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1844e-04\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.2743e-04\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1675e-04\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1110e-04\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0837e-04\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0576e-04\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1297e-04\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1345e-04\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1067e-04\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0979e-04\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0648e-04\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0017e-04\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0465e-04\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0165e-04\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0558e-04\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6740e-05\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0146e-04\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.4549e-05\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.1728e-05\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6144e-05\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.4948e-05\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.6518e-05\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 8.6773e-05\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.7555e-05\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.2181e-05\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.1185e-05\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.8134e-05\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.5920e-05\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.0497e-05\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.8230e-05\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.5960e-05\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.4605e-05\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.0351e-05\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.7627e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F55267D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F55267D08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0690e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7D1A2EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7D1A2EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0107\n",
      "Epoch 2/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0646e-04\n",
      "Epoch 3/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0161e-04\n",
      "Epoch 4/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.8754e-05\n",
      "Epoch 5/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.6566e-05\n",
      "Epoch 6/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.1399e-05\n",
      "Epoch 7/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0058e-04\n",
      "Epoch 8/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0491e-04\n",
      "Epoch 9/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6855e-05\n",
      "Epoch 10/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.7163e-05\n",
      "Epoch 11/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.1729e-04\n",
      "Epoch 12/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.8252e-05\n",
      "Epoch 13/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.4355e-05\n",
      "Epoch 14/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.0365e-05\n",
      "Epoch 15/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 1.0233e-04\n",
      "Epoch 16/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.5830e-05\n",
      "Epoch 17/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.3479e-05\n",
      "Epoch 18/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.1930e-05\n",
      "Epoch 19/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.2244e-05\n",
      "Epoch 20/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.2410e-05\n",
      "Epoch 21/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 9.6224e-05\n",
      "Epoch 22/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.3865e-05\n",
      "Epoch 23/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.3330e-05\n",
      "Epoch 24/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.1267e-05\n",
      "Epoch 25/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.8319e-05\n",
      "Epoch 26/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.8755e-05\n",
      "Epoch 27/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.6639e-05\n",
      "Epoch 28/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.8665e-05\n",
      "Epoch 29/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.7585e-05\n",
      "Epoch 30/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.8092e-05\n",
      "Epoch 31/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.4360e-05\n",
      "Epoch 32/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 8.1882e-05: 1s - loss: 7.3598\n",
      "Epoch 33/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.5588e-05\n",
      "Epoch 34/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.3383e-05\n",
      "Epoch 35/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.9926e-05\n",
      "Epoch 36/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.5691e-05\n",
      "Epoch 37/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.8394e-05A: 0s -\n",
      "Epoch 38/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 8.2602e-05\n",
      "Epoch 39/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.8009e-05\n",
      "Epoch 40/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 7.3468e-05\n",
      "Epoch 41/50\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.6790e-05\n",
      "Epoch 42/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.9617e-05\n",
      "Epoch 43/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.2135e-05\n",
      "Epoch 44/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.8463e-05\n",
      "Epoch 45/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.8742e-05\n",
      "Epoch 46/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.8629e-05\n",
      "Epoch 47/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 6.9271e-05\n",
      "Epoch 48/50\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 7.0786e-05\n",
      "Epoch 49/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 6.6665e-05\n",
      "Epoch 50/50\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 7.1454e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F78763B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F78763B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.7661e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F786EAEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F786EAEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0192\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2041e-04\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1604e-04\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1266e-04\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1457e-04\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1189e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1265e-04\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1262e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1075e-04\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2107e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1793e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1912e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1508e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2169e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0990e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2009e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1865e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1916e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1837e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1303e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2177e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1304e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1690e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1004e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1117e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7BF67B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7BF67B70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3055e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4F2C6400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F4F2C6400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0223\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2036e-04\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1078e-04\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1382e-04\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1464e-04\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0707e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1341e-04\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1689e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1804e-04\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1089e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.0814e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1688e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1406e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0300e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1806e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1009e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1682e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2000e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1299e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0755e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1011e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0171e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1784e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0518e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0509e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7E36D488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7E36D488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 3ms/step - loss: 3.6551e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7F47F400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7F47F400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0126\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 7.4345e-05\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.4099e-05\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 6.1512e-05\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.8085e-05\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.7968e-05\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.4610e-05\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 5.8275e-05\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.0905e-05\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.4112e-05\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.9928e-05\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.9548e-05\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.8224e-05\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.4985e-05\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.2412e-05\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 6.1024e-05\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 6.7105e-05\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.0250e-05\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 6.1033e-05\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.8887e-05\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.7597e-05\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.9700e-05\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.8568e-05\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 5.9424e-05\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 5.8409e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F788BC730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F788BC730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.6155e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F740BE378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F740BE378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0241\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.4488e-04\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2555e-04\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2560e-04\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2412e-04\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2446e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2572e-04\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2095e-04\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2426e-04\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2155e-04\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.3444e-04\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1881e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2948e-04\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2294e-04\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2814e-04\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2155e-04\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2016e-04\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2635e-04\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.2744e-04\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1842e-04\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.2783e-04\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1404e-04\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1264e-04\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1736e-04\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.1409e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F0EDE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4F0EDE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 7.2484e-05\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F468F98C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F468F98C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.0121\n",
      "Epoch 2/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 1.1609e-04\n",
      "Epoch 3/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0474e-04\n",
      "Epoch 4/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0142e-04\n",
      "Epoch 5/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.7777e-05\n",
      "Epoch 6/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0254e-04\n",
      "Epoch 7/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.7060e-05\n",
      "Epoch 8/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.5147e-05\n",
      "Epoch 9/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.7577e-05\n",
      "Epoch 10/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.5691e-05\n",
      "Epoch 11/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.3527e-05\n",
      "Epoch 12/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 1.0283e-04\n",
      "Epoch 13/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.9349e-05\n",
      "Epoch 14/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 9.1684e-05\n",
      "Epoch 15/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.2856e-05\n",
      "Epoch 16/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.7295e-05\n",
      "Epoch 17/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 8.9175e-05\n",
      "Epoch 18/25\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 9.6020e-05\n",
      "Epoch 19/25\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 8.6273e-05\n",
      "Epoch 20/25\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 9.2813e-05: 0s - loss: 9.344\n",
      "Epoch 21/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 9.1158e-05\n",
      "Epoch 22/25\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 8.6365e-05: 0s - los\n",
      "Epoch 23/25\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 8.7713e-05\n",
      "Epoch 24/25\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 8.9573e-05\n",
      "Epoch 25/25\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 9.1179e-05\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AEA0D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F4AEA0D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0230e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F73E48D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F73E48D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.0139\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.1703e-04\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 1.0839e-04\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0464e-04A: 0s - loss: 1.\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0520e-04\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0203e-04\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 1.0125e-04\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 1.0476e-04\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0450e-04\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1.0427e-04\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0087e-04\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.9606e-05\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 1.1232e-04\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0364e-04\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1.0261e-04\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1.0043e-04\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.0251e-04\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.8825e-05\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0217e-04\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0391e-04\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 9.6113e-05\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 9.7759e-05\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1.0024e-04\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.7859e-05\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 9.2943e-05\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 8.9610e-05\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 8.5287e-05\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 8.7507e-05\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.6404e-05\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 9.1299e-05\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 8.7645e-05\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 8.6279e-05\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 8.2520e-05\n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 8.7718e-05\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 9.0793e-05: 3s \n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 8.0196e-05\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 7.9459e-05\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.3163e-05\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 7.8021e-05\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 7.7651e-05\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 7.3039e-05\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 3s 11ms/step - loss: 7.2701e-05: 3s - loss: 8.104 - E - ETA: \n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.8979e-05\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.5472e-05\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.1984e-05\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 6.9701e-05\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.9079e-05\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.5715e-05\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.7745e-05\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 6.2787e-05\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "grid_search = RandomizedSearchCV(estimator = model,param_distributions=parameters,n_iter=5)\n",
    "# fitting the model and Calculating the best parameters.\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AA8E620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AA8E620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "268/268 [==============================] - 2s 7ms/step - loss: 0.0125\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1.0030e-04\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.7628e-05\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.7867e-05\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1.0008e-04\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 9.6250e-05\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0005e-04\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.7143e-05\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 1.0555e-04\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.9085e-05\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0118e-04\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 1.0011e-04\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.9544e-05\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.7144e-05\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 9.0279e-05\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.4201e-05\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 9.4417e-05\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.3440e-05\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.7595e-05\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.1146e-05\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.0608e-05\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.4861e-05\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.6370e-05\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 9.1303e-05\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.5034e-05\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.0515e-05\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 8.1959e-05\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 7.4180e-05\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 7.6729e-05\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.8742e-05\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.8413e-05\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.7612e-05\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.5812e-05\n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.2904e-05\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.0176e-05\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.1443e-05\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.9468e-05\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.7277e-05\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.2059e-05\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.8869e-05\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.6590e-05\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.7072e-05\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 5.8967e-05\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 6.0019e-05\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 5.7624e-05\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 5.4707e-05\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 5.4315e-05\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 5.8889e-05: 2s - loss:\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 5.7694e-05\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 5.3870e-05\n"
     ]
    }
   ],
   "source": [
    "model=grid_search.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000026F7ADCA8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000026F7ADCA8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "yhat = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.708984375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "y_pred = scaler.inverse_transform(yhat.reshape(-1,1))\n",
    "np.sqrt(mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### univariate sequence many to many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that segments the data\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04029304]\n",
      " [0.04029304]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]] \n",
      " Y:  [[0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]]\n",
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04029304]\n",
      " [0.04029304]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]] \n",
      " Y:  [[0.03663004]\n",
      " [0.03663004]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]]\n",
      "[[0.04175824]\n",
      " [0.04175824]\n",
      " [0.04175824]\n",
      " [0.04029304]\n",
      " [0.04029304]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03882784]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03736264]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]\n",
      " [0.03663004]] \n",
      " Y:  [[0.03663004]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.03443223]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.14285714]\n",
      " [0.03443223]]\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 30, 30\n",
    "n_features = 1\n",
    "\n",
    "# split the data into samples\n",
    "X, y = split_sequence(scaled_df, n_steps_in, n_steps_out)\n",
    "\n",
    "# print the first 3 samples for trainX and trainY\n",
    "for i in range(3):\n",
    "    print(X[i], \"\\n Y: \"  ,y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8571, 30, 1), (8571, 30, 1))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X[:int(len(X)-60),], X[int(len(X)-60):int(len(X)-30),], X[int(len(X)-30):,]\n",
    "y_train, y_valid, y_test = y[:int(len(X)-60),], y[int(len(X)-60):int(len(X)-30),], y[int(len(X)-30):,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8511, 30, 1),\n",
       " (30, 30, 1),\n",
       " (30, 30, 1),\n",
       " (8511, 30, 1),\n",
       " (30, 30, 1),\n",
       " (30, 30, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 30 (n_steps_out) predictions for each data point. \n",
    "# Thus, we need to take the predicitons on each 'n_steps_out' step \n",
    "X_valid, y_valid = X_test[::n_steps_out], y_test[::n_steps_out]\n",
    "X_test, y_test = X_test[::n_steps_out], y_test[::n_steps_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8511, 30, 1), (1, 30, 1), (1, 30, 1), (8511, 30, 1), (1, 30, 1), (1, 30, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "\n",
    "# define model\n",
    "\n",
    "def reg(optimizer):\n",
    "    regression = Sequential()\n",
    "    regression.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "    regression.add(LSTM(50, activation='relu'))\n",
    "    regression.add(Dense(1))\n",
    "    regression.compile(optimizer='adam', loss='mse')\n",
    "    return regression\n",
    "\n",
    "model= KerasRegressor(build_fn=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:282: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7CFEBEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7CFEBEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_162_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_162_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 11s 81ms/step - loss: 0.0137 0s - loss: \n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 10s 77ms/step - loss: 0.0013\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 11s 77ms/step - loss: 0.0013\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 11s 77ms/step - loss: 0.0012 0s - \n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 0.0012\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 0.0012\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 12s 85ms/step - loss: 0.0012\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 13s 92ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 0.0011\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 0.0011 1\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 0.0011\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 0.0011\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 0.0011\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 0.0010\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 11s 80ms/step - loss: 0.0010\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 9.9365e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 0.0010\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 9.8050e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 11s 83ms/step - loss: 0.0010\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 9.7315e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 9.8743e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 9.5374e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 9.5361e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 9.6394e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 9.2858e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 9.3018e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 9.4375e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 12s 85ms/step - loss: 9.3886e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 9.8338e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 9.7865e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 12s 90ms/step - loss: 9.0989e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 12s 84ms/step - loss: 9.1476e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.7974e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 9.3677e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 8.9333e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 11s 83ms/step - loss: 8.9942e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 10s 76ms/step - loss: 9.0835e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 9.3706e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.9763e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 8.9033e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.8999e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 14s 100ms/step - loss: 8.9593e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 13s 96ms/step - loss: 8.8267e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 12s 84ms/step - loss: 8.7690e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 12s 89ms/step - loss: 8.9253e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 13s 97ms/step - loss: 8.8200e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - ETA: 0s - loss: 8.8460e-0 - 11s 79ms/step - loss: 8.8458e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.7288e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 8.9409e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 8.5565e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AD91268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AD91268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_162_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 2.3009e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7E32B1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7E32B1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_164_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_164_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 11s 81ms/step - loss: 0.0168\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 0.0012\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 13s 98ms/step - loss: 0.0011\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 11s 83ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0010\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 0.0011\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.9336e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0010\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 0.0010\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 9.9532e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 9.7891e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.3253e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.6204e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.5893e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.8078e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 9.0211e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 8.8150e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 8.7633e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.7759e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.0284e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 8.7733e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 9.0283e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 8.8250e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.7743e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 8.7226e-04 0s - loss: 8.\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 8.8477e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 8.9475e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 8.7132e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.7303e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 8.4081e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 8.3817e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 8.7497e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.6501e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.5090e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 8.3225e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 10s 77ms/step - loss: 8.4213e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 8.5278e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 8.4561e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 8.2394e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.5814e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 8.5816e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 8.4114e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 8.1344e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.2956e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 9.0096e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.4192e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 8.1211e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7D2F8268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7D2F8268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_164_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 3.7628e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AD092F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7AD092F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_166_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_166_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0067\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 6.3582e-04\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 11s 79ms/step - loss: 5.7793e-04\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 10s 76ms/step - loss: 5.7863e-04\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 6.1490e-04\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 5.0610e-04\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 5.1225e-04\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 5.3998e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 10s 76ms/step - loss: 4.9277e-04 0s - loss: 5.\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 4.7053e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 4.8629e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 4.9233e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 5.0043e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 5.6817e-04: 0s - loss: 5\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 5.3909e-04\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 10s 70ms/step - loss: 5.0702e-04 1s\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 5.0917e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 5.1774e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 4.8753e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 4.5613e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 4.8575e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 4.6617e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 4.6619e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 4.3774e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 4.4150e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 4.3108e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 4.5734e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 4.8527e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 4.6294e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 4.4110e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 4.3922e-04\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 4.4313e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 4.7664e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 4.4964e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 4.3326e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 4.2086e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 4.1318e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 4.3097e-04: 1s - ETA: 0s - loss: \n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 4.1304e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 8s 59ms/step - loss: 3.9033e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 3.9693e-04: 0s - loss: 3.9904e-\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 4.0569e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 4.2864e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 4.1874e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 5.0205e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 4.3998e-04: 3s - loss:  - ETA: 2\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 4.1738e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 4.1568e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 4.1233e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 3.9026e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F02B03378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F02B03378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_166_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 0.0023\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F04EE5840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F04EE5840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_168_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_168_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0170\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0014\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0011\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0011\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0010\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0010\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0011\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.6801e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 9.9581e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 9.7954e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 11s 78ms/step - loss: 9.6731e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.7639e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 9.4624e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.5727e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 11s 77ms/step - loss: 9.7208e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 11s 77ms/step - loss: 9.4213e-04\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 10s 75ms/step - loss: 9.0727e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 9.3295e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 9.4112e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 9.6346e-04\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.5074e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.1400e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 9.3808e-04\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 8s 61ms/step - loss: 9.2824e-04: 0s - loss: 9.24\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.3971e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.0286e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.3358e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.3453e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 9.1583e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.8634e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 9.1531e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 8.9682e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.0007e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.8396e-04\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.8448e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 8.9055e-04\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.2352e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 12s 87ms/step - loss: 8.9985e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.7608e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 8.8513e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 9.1021e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 8.7734e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.7905e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7F3B6378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7F3B6378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_168_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 2.3128e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F01121400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F01121400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_170_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_170_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 0.0045\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0010\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - ETA: 0s - loss: 8.9383e-0 - 9s 67ms/step - loss: 8.9295e-04\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.8583e-04\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 8.8859e-04\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 8.4347e-04\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 8.2356e-04\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 7.6367e-04\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 8.1036e-04\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.4493e-04\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 7.8735e-04\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.3522e-04\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 7.1986e-04\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.5233e-04\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.5637e-04\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 7.4844e-04\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 7.3524e-04\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 6.9594e-04\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 7.1614e-04\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 7.0068e-04\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 7.4611e-04\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 6.8565e-04\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.9862e-04: 0s - loss: 6.9922e-0\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.7842e-04\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 6.8643e-04\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.9921e-04\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.8301e-04: 1s - \n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.6975e-04\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.8976e-04\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.7879e-04\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.9370e-04: 0s - loss: 6.877\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - ETA: 0s - loss: 7.1448e-0 - 8s 62ms/step - loss: 7.1646e-04\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.8366e-04\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.8570e-04\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.5806e-04\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.7356e-04\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.6307e-04\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.6127e-04\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.5038e-04\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.6553e-04\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.6243e-04: 1s - loss: 6.64 - ETA: 1s -  - ETA: 0s - loss: 6.6435\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.4384e-04\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.7281e-04\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 9s 63ms/step - loss: 7.0923e-04\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.3290e-04\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.4954e-04\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.4508e-04\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.3990e-04\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.5669e-04\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 6.3162e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AD91488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7AD91488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_170_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 0.0019\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7A9B92F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7A9B92F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_172_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_172_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 0.0141\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 0.0012\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0011\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 0.0011\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 0.0010\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0010\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 0.0010\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 0.0010: 0s - loss: 0.0\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0010\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0010\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.8375e-04\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.5822e-04\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.7552e-04\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.9641e-04\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.5218e-04\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.6558e-04\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.5942e-04: 4s  - ETA: 3s  - ETA: 2s - loss: 9.2607e-0 - ETA: 2s - lo - \n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.4972e-04\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.7080e-04\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.4004e-04\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.6836e-04\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 9.3758e-04\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.2904e-04\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.5071e-04\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.0888e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71D6BEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71D6BEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_172_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 2.0939e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F529AC158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F529AC158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_174_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_174_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 0.0095\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0012\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 0.0012\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0011: 0\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 9s 63ms/step - loss: 0.0011\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 0.0011\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0010\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.5070e-04\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 9.8329e-04\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.7096e-04\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.9729e-04: 0s - loss: 9.9679e-\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 9.4441e-04\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.3252e-04\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.3110e-04: 0s - loss: 9.33\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.1337e-04\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 9.3260e-04\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.1871e-04\n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.5553e-04\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.2945e-04\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.0792e-04\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 9.0494e-04: 0s - loss: 9.\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 8.8789e-04\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 8.9015e-04\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 8.7747e-04\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 8s 60ms/step - loss: 8.8821e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F52B9F6A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F52B9F6A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_174_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 4.1171e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F5768D620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F5768D620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_176_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_176_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 0.0095\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 8s 62ms/step - loss: 7.0104e-04\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 6.4214e-04\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 6.1414e-04\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 6.0592e-04\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 5.5077e-04\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 5.0342e-04\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 5.8970e-04\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 6.1283e-04\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 5.8054e-04\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 5.5166e-04\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 5.3996e-04\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 5.4596e-04\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 8s 61ms/step - loss: 5.1460e-04\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 5.1279e-04\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 4.7705e-04\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 10s 73ms/step - loss: 5.2527e-04\n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 4.8830e-04\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 10s 76ms/step - loss: 4.9762e-04\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 4.7249e-04\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 4.5121e-04\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 4.5136e-04\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 4.3629e-04\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 4.6464e-04\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 4.3915e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F65CA5840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F65CA5840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_176_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 0.0023\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70A3BAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F70A3BAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_178_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_178_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.0178\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0014\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.0013\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 0.0013\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 10s 71ms/step - loss: 0.0012\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 0.0012\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 0.0012\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 10s 72ms/step - loss: 0.0011\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 0.0011\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0011\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 0.0011\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 10s 74ms/step - loss: 0.0011\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 11s 82ms/step - loss: 0.0010\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 10s 70ms/step - loss: 0.0010\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 9s 69ms/step - loss: 9.7591e-04\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 0.0010\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 9.9423e-04\n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.7476e-04\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 9.9162e-04\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 9s 67ms/step - loss: 9.8323e-04\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 9.9845e-04\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.6777e-04\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 9.8861e-04\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 9s 62ms/step - loss: 9.5079e-04\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 9.5459e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F775BB400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F775BB400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_178_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 1.3576e-04\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F52D55378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F52D55378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_180_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_180_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 0.0071\n",
      "Epoch 2/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 9.7157e-04\n",
      "Epoch 3/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 8.9082e-04\n",
      "Epoch 4/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.8529e-04\n",
      "Epoch 5/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 8.7564e-04\n",
      "Epoch 6/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.2161e-04\n",
      "Epoch 7/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 7.9523e-04\n",
      "Epoch 8/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 8.0884e-04\n",
      "Epoch 9/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 7.4700e-04\n",
      "Epoch 10/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 7.6910e-04\n",
      "Epoch 11/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.1695e-04\n",
      "Epoch 12/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.1690e-04\n",
      "Epoch 13/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.0727e-04\n",
      "Epoch 14/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.0805e-04\n",
      "Epoch 15/25\n",
      "137/137 [==============================] - 9s 63ms/step - loss: 7.2438e-04\n",
      "Epoch 16/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.1096e-04\n",
      "Epoch 17/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.2647e-04\n",
      "Epoch 18/25\n",
      "137/137 [==============================] - 9s 68ms/step - loss: 7.0936e-04\n",
      "Epoch 19/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.0120e-04\n",
      "Epoch 20/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 7.0264e-04\n",
      "Epoch 21/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 7.0502e-04\n",
      "Epoch 22/25\n",
      "137/137 [==============================] - 9s 64ms/step - loss: 7.2132e-04\n",
      "Epoch 23/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 6.8350e-04\n",
      "Epoch 24/25\n",
      "137/137 [==============================] - 9s 65ms/step - loss: 6.8397e-04\n",
      "Epoch 25/25\n",
      "137/137 [==============================] - 9s 66ms/step - loss: 6.9259e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F00FF8400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F00FF8400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_180_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 23ms/step - loss: 0.0013\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F0108B488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F0108B488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_182_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_182_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0114\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0013\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0012\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0011 0s - loss: 0.\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0010\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0010\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.9536e-04\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0010\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.8719e-04\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.7903e-04 3s - loss - ETA: 0s - loss: 9.780 - ETA: 0s - loss: \n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.7905e-04\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.8573e-04\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.7338e-04\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.9340e-04\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.4834e-04\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.4409e-04\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.3483e-04\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.1016e-04\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 9.2767e-04\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.1864e-04\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0010\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.1781e-04\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 14s 66ms/step - loss: 9.1461e-04\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 14s 67ms/step - loss: 9.0709e-04\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 14s 66ms/step - loss: 9.0880e-04\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.2866e-04\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 9.3503e-04\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.8752e-04\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.9582e-04\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 8.9851e-04\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 13s 62ms/step - loss: 9.0116e-04\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 8.8438e-04\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.8365e-04\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 11s 54ms/step - loss: 8.6874e-04\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 11s 54ms/step - loss: 8.7029e-04\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 11s 54ms/step - loss: 8.8576e-04\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 12s 54ms/step - loss: 8.6233e-04\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.5674e-04\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 13s 62ms/step - loss: 8.9460e-04\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.6609e-04\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 11s 54ms/step - loss: 8.7162e-04\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.6623e-04\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 12s 54ms/step - loss: 8.4178e-04\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 8.5833e-04\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 8.4903e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F06562510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F06562510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_182_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 3.3224e-04\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F076CE400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F076CE400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_184_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_184_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 12s 56ms/step - loss: 0.0082\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0012\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0012\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 0.0010\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.0010\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.9261e-04 0s - loss: 9.87\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 15s 70ms/step - loss: 0.0010\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 14s 67ms/step - loss: 9.3401e-04\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.1245e-04\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 9.3037e-04\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 15s 68ms/step - loss: 9.3347e-04\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.3028e-04\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.1836e-04\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.3098e-04 2s  - ETA: 1\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.8291e-04\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 9.0037e-04\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.0184e-04\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.7177e-04\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.7817e-04\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.9234e-04\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.7861e-04\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.8127e-04\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.7625e-04\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.7532e-04\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.4545e-04\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.4935e-04\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.4479e-04\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.5063e-04\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.4403e-04\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.3769e-04\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.2472e-04 0s - loss: \n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.3329e-04\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.3854e-04\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.1739e-04\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.1288e-04 0s - loss: 8.1580e\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.1095e-04\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.2372e-04\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.1913e-04\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.0895e-04\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.0742e-04\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.2391e-04\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.3496e-04\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.0284e-04\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.1222e-04\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.1029e-04\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.2380e-04\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 7.8892e-04\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 7.8071e-04\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 7.8440e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F06562F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F06562F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_184_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.7448e-04: 0s - loss: \n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F010C9D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F010C9D90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_186_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_186_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0065\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 6.6439e-04\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 6.2998e-04 0s - loss: 6.4 - ETA: 0s - loss: 6.361\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 5.6781e-04\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 6.0995e-04\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.4569e-04\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 6.4247e-04\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 5.6060e-04\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.2866e-04\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 5.5494e-04\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 5.4001e-04\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.5539e-04\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.4150e-04 0s - loss: 5.4451e\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 12s 58ms/step - loss: 4.9236e-04\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.9294e-04\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 5.6129e-04\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 6.0116e-04\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.5294e-04\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 5.2979e-04\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 5.1866e-04\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 5.1103e-04\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.8595e-04\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 4.9008e-04\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.7905e-04\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.7010e-04\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 4.3544e-04\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.2592e-04\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.5196e-04\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.5136e-04\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.6346e-04\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.3220e-04\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.2577e-04\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.6539e-04 0s - loss: 4.6539e-0\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.2375e-04\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 4.0919e-04\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.2253e-04\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.2080e-04\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.0832e-04\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.3236e-04\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.1133e-04\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.0541e-04\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 4.1732e-04\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 4.1807e-04\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 3.9734e-04\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.1621e-04\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 4.0795e-04\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 3.9883e-04\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 4.0602e-04\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.0340e-04\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 4.0884e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71D9F1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F71D9F1E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_186_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0022\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7BF67A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F7BF67A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_188_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_188_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 0.0092\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 0.0012\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 0.0011\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 0.0011\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 0.0010\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 9.8352e-04\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 0.0010\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 0.0010\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.9585e-04\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.7831e-04\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.6458e-04\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.5959e-04\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.9966e-04 0s - loss\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.5996e-04\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.5882e-04\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.9207e-04\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.7422e-04\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.9474e-04\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 9.6714e-04\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.5028e-04\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 9.4905e-04\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.2144e-04\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 14s 65ms/step - loss: 9.3818e-04\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 13s 62ms/step - loss: 9.1579e-04 ETA: 0s - loss: 9.24\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.6354e-04\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.1218e-04\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.1868e-04\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.0223e-04\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.0136e-04\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.9385e-04 1\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.0271e-04\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.0079e-04\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 8.9547e-04\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.1262e-04 0s - loss:  - ETA: 0s - loss: 9.1292e-\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 8.8784e-04\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.9093e-04\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.2146e-04\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.3973e-04\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 9.2139e-04\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.2369e-04\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 8.8982e-04\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 9.0862e-04 0s - loss\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 8.9032e-04\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 14s 66ms/step - loss: 8.8947e-04\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 15s 71ms/step - loss: 8.7988e-04\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7889AE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026F7889AE18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_188_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 6.5400e-05\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F529E1F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026F529E1F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_190_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 1) for input Tensor(\"lstm_190_input:0\", shape=(None, 3, 1), dtype=float32), but it was called on an input with incompatible shape (None, 30, 1).\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 0.0052\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 9.1843e-04\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 8.6963e-04\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 8.5662e-04\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 8.2757e-04\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 8.0649e-04\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 7.2930e-04\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 7.3096e-04\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 7.3534e-04\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 7.5432e-04\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 7.1820e-04\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 7.2373e-04\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 7.2076e-04\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 7.0821e-04\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 7.2631e-04\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 12s 55ms/step - loss: 7.0514e-04\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 11s 54ms/step - loss: 7.1672e-04\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 7.0125e-04\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 13s 59ms/step - loss: 7.0306e-04\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 7.0107e-04\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 7.0427e-04\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 14s 66ms/step - loss: 6.9641e-04\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 13s 60ms/step - loss: 6.9909e-04\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 12s 58ms/step - loss: 6.8048e-04\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 13s 61ms/step - loss: 6.7121e-04 1s - loss: 6.7 - ETA: 0s - loss: 6.7 - ETA: 0s - loss: 6.753\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 12s 56ms/step - loss: 6.6501e-04\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 14s 65ms/step - loss: 6.8074e-04\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 14s 65ms/step - loss: 6.5924e-04 3s - loss: 6.7 - ETA: \n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 14s 64ms/step - loss: 6.6819e-04\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 13s 63ms/step - loss: 6.8379e-04 0s - loss: 6\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 6.7011e-04\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 12s 59ms/step - loss: 6.6058e-04 0s - loss: 6.6173e-\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 14s 65ms/step - loss: 6.4535e-04\n",
      "Epoch 34/50\n",
      "165/213 [======================>.......] - ETA: 3s - loss: 6.5854e-04"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "grid_search = RandomizedSearchCV(estimator = model,param_distributions=parameters,n_iter=5)\n",
    "# fitting the model and Calculating the best parameters.\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "yhat = grid_search.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = yhat.reshape(yhat.shape[0]*yhat.shape[1],1)\n",
    "y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368.4492128354552"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = scaler.inverse_transform(y_test)\n",
    "y_pred = scaler.inverse_transform(yhat)\n",
    "np.sqrt(mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.reshape(y_train_pred.shape[0]*y_train_pred.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = grid_search.predict(X_valid)\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred.reshape(y_valid_pred.shape[0]*y_valid_pred.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the test data and predicitons\n",
    "plt.plot(y_actual)\n",
    "plt.plot(y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the data\n",
    "train_actual = scaler.inverse_transform(y_train.reshape(y_train.shape[0]*y_train.shape[1],1))\n",
    "valid_actual = scaler.inverse_transform(y_valid.reshape(y_valid.shape[0]*y_valid.shape[1],1))\n",
    "test_actual = scaler.inverse_transform(y_test.reshape(y_test.shape[0]*y_test.shape[1],1))\n",
    "#valid['Predictions'] = predictions\n",
    "#Visualize the Plot\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Closing Price in (MKD)', fontsize=18)\n",
    "#plt.plot(train)\n",
    "#plt.plot(train_actual)\n",
    "#plt.plot(y_train_pred)\n",
    "plt.plot(test_actual)\n",
    "plt.plot(y_pred)\n",
    "plt.legend(['Train','Val'], loc= 'lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
